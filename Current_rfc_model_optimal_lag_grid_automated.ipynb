{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be91c30-a5e9-4785-992a-60321b848f4f",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Optimal Feature Lag, Model Parameters, & Strategy Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65360a93-3514-4354-b5ea-02fc3039d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This notebook uses nieve parameter settings (naive will be compared against grid search averages) over numerous feature set lags (1 - 90 days)\n",
    "#### n_estimators = 500\n",
    "#### max_depth = 5000\n",
    "#### max_features = 5\n",
    "#### min_samples_split = 2\n",
    "\n",
    "#### This notebook uses RandomizedSearchCV to determine 'optimal' model parameters, which are then averaged \n",
    "#### The average parameter values across all lags are then used within notebook 'Current_rfc_model_algo_optimal_params_all_avg.ipynb' to determine if optimal is superior to nieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96c045-2f13-47f3-a47a-391dca5b323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Resource:    https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#                    https://github.com/scikit-learn/scikit-learn/blob/844b4be24/sklearn/ensemble/_forest.py#L1064 (code)\n",
    "# Pyfolio Resource:  https://www.quantrocket.com/codeload/quant-finance-lectures/quant_finance_lectures/Lecture33-Portfolio-Analysis-with-pyfolio.ipynb.html\n",
    "# Understanding the shift can be confusing when analyzing results.  This reference does a good job explaining (index is not shifted, only the column values):  https://datascienceparichay.com/article/pandas-shift-column-values-up-or-down/\n",
    "# https://mljar.com/blog/save-load-random-forest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0dc50e-ff8d-4396-9dd3-a610f80da6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Set Variables\n",
    "# ICE BofA US High Yield Index Option-Adjusted Spread (BAMLH0A0HYM2)\n",
    "# ICE BofA US Corporate Index Option-Adjusted Spread (BAMLC0A0CM)\n",
    "# ICE BofA BBB US Corporate Index Option-Adjusted Spread (BAMLC0A4CBBB)\n",
    "# ICE BofA BB US High Yield Index Option-Adjusted Spread (BAMLH0A1HYBB)\n",
    "# ICE BofA CCC & Lower US High Yield Index Option-Adjusted Spread (BAMLH0A3HYC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3d1fc-733c-4393-a8e0-7cba31c607ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "import hvplot.pandas\n",
    "\n",
    "#Import SKLearn Library and CLasses\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import yfinance as yf\n",
    "import pyfolio as pf\n",
    "from pyfolio import timeseries \n",
    "import matplotlib.pyplot as plt\n",
    "import empyrical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fbac2-0c37-4b60-bdd0-65dea69a0ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values in this DataFrame are objects; proper data types are cast within the 'for loop\" portion of code or hardcoded\n",
    "df_random_forest_model_param = pd.read_csv('ManualFiles/random_forest_nieve_model_parameters.csv', index_col=0)\n",
    "df_random_forest_model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ef763-3e4d-4e80-b62e-6ec403ba31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Parameters for reference purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68946070-4c12-4399-a10c-6b57c0e00c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = ''\n",
    "msg +=('class sklearn.ensemble.RandomForestClassifier(\\n')\n",
    "msg +=('    n_estimators=100, \\n')\n",
    "msg +=('    *, \\n')\n",
    "msg +=('    criterion=\"gini\", \\n')\n",
    "msg +=('    max_depth=None, \\n')\n",
    "msg +=('    min_samples_split=2, \\n')\n",
    "msg +=('    min_samples_leaf=1, \\n')\n",
    "msg +=('    min_weight_fraction_leaf=0.0, \\n')\n",
    "msg +=('    max_features=\"auto\", \\n')\n",
    "msg +=('    max_leaf_nodes=None, \\n')\n",
    "msg +=('    min_impurity_decrease=0.0, \\n')\n",
    "msg +=('    bootstrap=True, \\n')\n",
    "msg +=('    oob_score=False, \\n')\n",
    "msg +=('    n_jobs=None, \\n')\n",
    "msg +=('    random_state=None, \\n')\n",
    "msg +=('    verbose=0, \\n')\n",
    "msg +=('    warm_start=False, \\n')\n",
    "msg +=('    class_weight=None, \\n')\n",
    "msg +=('    ccp_alpha=0.0, \\n')\n",
    "msg +=('    max_samples=None \\n')\n",
    "msg +=(')')\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b910a-36fd-4945-829f-acf02b402317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of shift for feature set\n",
    "signal_shift_range = range(1,91)\n",
    "\n",
    "# Run date included in data frame construction below\n",
    "run_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Instantiate result list to hold pyfolio performance results for strategy\n",
    "results_list = []\n",
    "\n",
    "# Instantiate best paramter list for feature lags\n",
    "best_params_list = []\n",
    "\n",
    "# Instantiate capture statistics for feature lags\n",
    "capture_stats_list = []\n",
    "\n",
    "# Note:  Sufficient historical data exists when shifting the dataset by \"i\" days will produce the same test data lengths\n",
    "# testing_start = '2018-12-15' is hardcoded (test period length with expand on each subsequent day's testing of strategy results)\n",
    "# First testing period = 713 days\n",
    "\n",
    "for i in signal_shift_range:\n",
    "    print(f'\\n****************** RUNNING FEATURE LAG {i} ******************')\n",
    "        \n",
    "    # Open signals file for feature set; prior version placement outside of for loop, but that was leading to incorrect results\n",
    "    # Full process and logic now included in for loop\n",
    "    # Open signals file for feature set\n",
    "\n",
    "    feature_set_pct_path = Path('AutoOutputFiles/df_key_credit_data_usa_adjusted_pct.csv')\n",
    "    X = pd.read_csv(feature_set_pct_path, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "    # Uncomment if required for testing\n",
    "    #print(f'Feature set prior to shift\\n')\n",
    "    #print(X.head())\n",
    "    \n",
    "    # Shift feature set\n",
    "    X = X.shift(i).dropna()\n",
    "    # Uncomment if required for testing\n",
    "    #print(f'\\nFeature set post shift\\n')\n",
    "    #print(X.head())\n",
    "\n",
    "    target_set_levels_path = Path('AutoOutputFiles/df_equity_data.csv')\n",
    "    equity_data = pd.read_csv(target_set_levels_path, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "    # Uncomment if required for testing\n",
    "    #print(f'\\nTarget set on import:\\n')\n",
    "    #print(equity_data.head())\n",
    "\n",
    "    df_trading_signals = pd.concat([equity_data, X], axis='columns', join='inner')\n",
    "    # Uncomment if required for testing\n",
    "    #print(f'\\nTrading Signals DataFrame used for modelling:\\n')\n",
    "    #print(df_trading_signals.head())\n",
    "\n",
    "    # Manually Split into training and test datasets\n",
    "    training_start = df_trading_signals.index.min().strftime(format='%Y-%m-%d')\n",
    "    training_end = '2018-12-14'\n",
    "\n",
    "    testing_start = '2018-12-15'\n",
    "    testing_end = df_trading_signals.index.max().strftime(format='%Y-%m-%d')\n",
    "    \n",
    "    # Define X variable list\n",
    "    x_variables = ['BAMLH0A0HYM2', 'BAMLC0A0CM', 'BAMLC0A4CBBB','BAMLH0A1HYBB', 'BAMLH0A3HYC']\n",
    "         \n",
    "    # X & Y Training Datasets\n",
    "    x_train = df_trading_signals[x_variables][training_start:training_end]\n",
    "    y_train = df_trading_signals['PositiveReturn'][training_start:training_end]\n",
    "    # Uncomment if required for testing\n",
    "    #print(f'\\nx_train = {x_train}')\n",
    "    #print(f'\\ny_train = {y_train}')     \n",
    "    \n",
    "    # X and Y Testing Datasets\n",
    "    x_test = df_trading_signals[x_variables][testing_start:testing_end]\n",
    "    y_test = df_trading_signals['PositiveReturn'][testing_start:testing_end]\n",
    "    # Uncomment if required for testing\n",
    "    #print(f'\\nx_test = {x_test}')\n",
    "    #print(f'\\ny_test = {y_test}')\n",
    "    \n",
    "    # RandomizedSearchCV for current lagged feature set\n",
    "    # Used to determine mean values for best_param\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=0)\n",
    "    input_cv_value = 5\n",
    "    input_random_state = 0\n",
    "    input_return_train_score = True\n",
    "\n",
    "    forest_params = [\n",
    "        {\n",
    "            'max_depth': list(range(9, 6001)), \n",
    "            'max_features': list(range(1,6)),     # Future Enhancements:  Remove this model restriction\n",
    "            'n_estimators': list(range(1,1001)),  # Future Enhancements:  Starting at 30 (statistically significant level at 30 data point); 1 would be a simple decision tree\n",
    "            'min_samples_split': list(range(1,51))\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    rgs = RandomizedSearchCV(rfc, forest_params, cv=input_cv_value, scoring='accuracy', return_train_score=input_return_train_score)\n",
    "    \n",
    "    rgs.fit(x_train, y_train)\n",
    "    \n",
    "    # best_params_ = dictionary\n",
    "    best_params = rgs.best_params_\n",
    "    \n",
    "    # Append current iteration's best_params_ (list of lists will be used to construct this data frame)\n",
    "    best_params_list.append(\n",
    "        [\n",
    "            run_date,\n",
    "            testing_end,  # This also represents the period end date\n",
    "            i, \n",
    "            best_params\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Uncomment if required for testing\n",
    "    #print('\\ncurrent best_params_list')\n",
    "    #print(best_params_list)\n",
    "    #print('')\n",
    "    \n",
    "    # Model Parameters used for df_strat_lag\n",
    "    input_n_estimators = int(df_random_forest_model_param.loc['n_estimators'].values)\n",
    "    input_max_depth = int(df_random_forest_model_param.loc['max_depth'].values)\n",
    "    input_max_features = 'auto'\n",
    "    input_random_state = int(df_random_forest_model_param.loc['random_state'].values)\n",
    "    input_verbose = int(df_random_forest_model_param.loc['verbose'].values)    \n",
    "\n",
    "    # Instantiate, Define, & fit the model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators = input_n_estimators,\n",
    "        max_depth = input_max_depth, \n",
    "        max_features = input_max_features, \n",
    "        random_state = input_random_state, \n",
    "        verbose = input_verbose\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Make a prediction of \"y\" values from the x test dataset\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # Assesmble actual y data (y_test) with predicted y data (from just above) into two columns in a dataframe:\n",
    "    results = y_test.to_frame()\n",
    "    results['PredictedValue'] = predictions\n",
    "\n",
    "    # Add a difference column to data frame\n",
    "    results['PredictedMinusActual'] = results['PredictedValue'] - results['PositiveReturn']\n",
    "    \n",
    "    # This column already exists in results data frame\n",
    "    df_trading_signals.drop(columns=['PositiveReturn'], inplace=True)\n",
    "\n",
    "    df_performance_results = pd.concat([results, df_trading_signals], axis='columns', join='inner')\n",
    "    df_performance_results['Equity_Position'] = df_performance_results['PredictedValue'] * df_performance_results['EquityPriceReturns']\n",
    "    df_performance_results['Strategy_Cum_Rtn'] = ( 1 + df_performance_results['Equity_Position']).cumprod()\n",
    "    df_performance_results['Equity_Cum_Rtn'] = ( 1 + df_performance_results['EquityPriceReturns']).cumprod()\n",
    "    \n",
    "    # Save each iteration as a csv file in folder AutoOutputFiles and append period end date to file\n",
    "    fl_nm = 'AutoOutputFiles/Lag_' + str(i) + '_df_performance_results_' + testing_end + '.csv'\n",
    "\n",
    "    df_performance_results.to_csv(fl_nm)\n",
    "\n",
    "    # Modify data frame dates to conform to Pyfolio date requirements\n",
    "    df_pyfolio = df_performance_results\n",
    "    df_pyfolio = df_pyfolio.tz_localize(\"UTC\")\n",
    "\n",
    "    algo_performance_series = df_pyfolio['Equity_Position']\n",
    "    \n",
    "    # This is only required to produce stats related to index (i.e. beta, alpha, etc)\n",
    "    Equity_performance_series = df_pyfolio['EquityPriceReturns']\n",
    "\n",
    "    perf_func = timeseries.perf_stats \n",
    "    perf_stats_all = perf_func(returns=algo_performance_series, factor_returns=Equity_performance_series, positions=None, transactions=None, turnover_denom=\"USD\")\n",
    "\n",
    "    # We don't need the index performance each time - will be obtained in rfc_model once optimal shift has been determined\n",
    "\n",
    "    # Append each iterations results to results_list which is later used to construct a data frame\n",
    "    results_list.append(\n",
    "        [\n",
    "            run_date,\n",
    "            testing_end,  # This also represents the period end date\n",
    "            i,\n",
    "            input_n_estimators,\n",
    "            input_max_depth,\n",
    "            input_max_features,\n",
    "            input_random_state,\n",
    "            input_verbose,            \n",
    "            empyrical.annual_return(algo_performance_series),\n",
    "            empyrical.annual_volatility(algo_performance_series),\n",
    "            empyrical.sharpe_ratio(algo_performance_series),\n",
    "            empyrical.calmar_ratio(algo_performance_series),\n",
    "            empyrical.max_drawdown(algo_performance_series),\n",
    "            empyrical.sortino_ratio(algo_performance_series),\n",
    "            empyrical.alpha(algo_performance_series,Equity_performance_series),\n",
    "            empyrical.beta(algo_performance_series,Equity_performance_series)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Describe return days and strategy capture for these return days\n",
    "    # Calculate the number of total trading days in test period (investable days)\n",
    "    # Using PredictedValue column which contains 0 & 1 values, thus count function used and not sum function\n",
    "    total_days = df_performance_results['PredictedValue'].count()\n",
    "    #print(f'The total number of days in the testing period = {total_days}')\n",
    "\n",
    "    # Calculate the total number of postiive trading days in test period\n",
    "    # Using PositiveReturn column which contains 0 & 1 values; since we are only interested in values = 1, we can use sum function\n",
    "    # Calculate the % of positive trading days as function of total trading days\n",
    "    total_pos_days = df_performance_results.loc[(df_performance_results['PositiveReturn'] == 1), 'PositiveReturn'].sum()\n",
    "    total_pos_days_pct = total_pos_days / total_days\n",
    "    total_pos_days_pct\n",
    "    #print(f'The total number of postive return days in the testing period = {total_pos_days} or {total_pos_days_pct:.3%} of total days')\n",
    "\n",
    "    # Calculate the total number of negative trading days in period\n",
    "    # We can subtract total positive days from total days\n",
    "    # Calculate the % of negative trading days as a function of total trading days\n",
    "    total_neg_days = total_days - total_pos_days\n",
    "    total_neg_days_pct = total_neg_days / total_days\n",
    "    #print(f'The total number of postive return days in the testing period = {total_neg_days} or {total_neg_days_pct:.3%} of total days')\n",
    "\n",
    "    # Calculate the number of days the strategy predictive a positive equity return day (days invested in equity security) \n",
    "    # We can use the sum function as invested days = PredictedValue of 1 (negative days = 0)\n",
    "    # Calculate the % of invested days as a function of total trading days\n",
    "    strat_days_invested = df_performance_results['PredictedValue'].sum()\n",
    "    strat_days_invested_pct = strat_days_invested / total_days\n",
    "    #print(f'The strategy had a long positions in the equity on {strat_days_invested} or {strat_days_invested_pct:.3%} of total days')\n",
    "\n",
    "    # Calculate the number of days invested in cash\n",
    "    # We can subtract invested days from total days to determine value\n",
    "    strat_days_in_cash = total_days - strat_days_invested\n",
    "    strat_days_in_cash_pct = 1 - strat_days_invested_pct\n",
    "    #print(f'The strategy had long positions in cash on {strat_days_in_cash} or {strat_days_in_cash_pct:.3%} of total days')\n",
    "\n",
    "    # Upside Capture\n",
    "    # Calculate the number of days where invested in equity security and equity security had a positive return day\n",
    "    strat_days_invested_positive = df_performance_results.loc[(df_performance_results['PositiveReturn'] == 1) & (df_performance_results['PredictedValue'] == 1), 'PredictedValue'].count()\n",
    "    strat_days_invested_positive_pct = strat_days_invested_positive / total_pos_days\n",
    "    #print(f'The strategy captured {strat_days_invested_positive} of the equities postive return days or {strat_days_invested_positive_pct:.3%}')\n",
    "\n",
    "    # Downside Capture\n",
    "    # Calculate the number of days where invested in equity security and the equity security had a negative return day\n",
    "    strat_days_invested_negative = df_performance_results.loc[(df_performance_results['PositiveReturn'] == 0) & (df_performance_results['PredictedValue'] == 0), 'PredictedValue'].count()\n",
    "    strat_days_invested_negative_pct = strat_days_invested_negative / total_neg_days\n",
    "    #print(f'The strategy captured {strat_days_invested_negative} of the equities negative return days or {strat_days_invested_negative_pct:.3%}')\n",
    "\n",
    "    # Total days where equity delivered return greater than or equal to 1%\n",
    "    total_days_pos_extreme = df_performance_results.loc[(df_performance_results['EquityPriceReturns'] >= 0.01), 'EquityPriceReturns'].count()\n",
    "    #print(f'\\nTotal days where equity delivered a return greater than or equal to 1%:  {total_days_pos_extreme}')\n",
    "\n",
    "    # Total days where equity delivered return less than or equal to -1%\n",
    "    total_days_neg_extreme = df_performance_results.loc[(df_performance_results['EquityPriceReturns'] <= -0.01), 'EquityPriceReturns'].count()\n",
    "    #print(f'Total days where equity delivered a return less than or equal to -1%:  {total_days_neg_extreme}')\n",
    "\n",
    "    # Total days the strategy captured positive extreme return days\n",
    "    total_days_pos_extreme_invested = df_performance_results.loc[(df_performance_results['EquityPriceReturns'] >= 0.01) & (df_performance_results['PredictedValue'] == 1), 'EquityPriceReturns'].count()\n",
    "    #print(f'Total days the strategy captured positive extreme return days (>= 1%): {total_days_pos_extreme_invested}')\n",
    "\n",
    "    # Total days the strategy captured negative extreme return days\n",
    "    total_days_neg_extreme_invested = df_performance_results.loc[(df_performance_results['EquityPriceReturns'] <= -0.01) & (df_performance_results['PredictedValue'] == 1), 'EquityPriceReturns'].count()\n",
    "    #print(f'Total days the strategy captured negative extreme return days (<= -1%): {total_days_neg_extreme_invested}')\n",
    "    \n",
    "    # Append each iterations results to results_list which is later used to construct a data frame\n",
    "    capture_stats_list.append(\n",
    "        [\n",
    "            run_date,\n",
    "            testing_end,  # This also represents the period end date\n",
    "            i,\n",
    "            total_days,\n",
    "            total_pos_days,\n",
    "            total_neg_days,\n",
    "            strat_days_invested,\n",
    "            strat_days_in_cash,            \n",
    "            strat_days_invested_positive,\n",
    "            strat_days_invested_negative,\n",
    "            total_days_pos_extreme,\n",
    "            total_days_neg_extreme,\n",
    "            total_days_pos_extreme_invested,\n",
    "            total_days_neg_extreme_invested\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # save the model\n",
    "    # The first argument of the method is variable with the model. The second argument is the path and the file name where the resulting file will be created.\n",
    "    fl_nm = 'model_candidates/nieve/Lag_' + str(i) + '_random_forest_' + testing_end + '.joblib'\n",
    "    joblib.dump(model, fl_nm, compress=3)\n",
    "    \n",
    "    del X\n",
    "    del equity_data\n",
    "    del df_trading_signals\n",
    "    del results\n",
    "    del df_performance_results\n",
    "    del df_pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b35cd4-28f1-4f29-80b5-3c0f5ff8e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_dict_values(**kwargs):\n",
    "    ''' Function that accept dictionay key word arguements and unpacks to variables '''\n",
    "    if 'n_estimators' in kwargs:\n",
    "        n_estimators =  kwargs['n_estimators']\n",
    "        print(\"n_estimators: \", kwargs['n_estimators'])\n",
    "    \n",
    "    if 'min_samples_split' in kwargs:\n",
    "        min_samples_split = kwargs['min_samples_split']\n",
    "        print(\"min_samples_split : \", kwargs['min_samples_split'])\n",
    "    \n",
    "    if 'max_features' in kwargs:\n",
    "        max_features = kwargs['max_features']\n",
    "        print(\"max_features : \", kwargs['max_features'])\n",
    "    \n",
    "    if 'max_depth' in kwargs:\n",
    "        max_depth = kwargs['max_depth']\n",
    "        print(\"max_depth : \", kwargs['max_depth'])\n",
    "    \n",
    "    return n_estimators, min_samples_split, max_features, max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea50bf-3b3e-4a2f-8d72-7c1c276a3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment during testing to confirm list was constructed correctly or for future enhancements\n",
    "best_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f8f10-bd3a-45a5-a24e-f95213a9922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming best_params_list data structure to list of list to make DataFrame construction simpler\n",
    "# best_params_list is a list of lists but also contains a dictionary of values (constructing the data frame form this data structure too complicated for my skill set)\n",
    "\n",
    "# List of lists to store values from best_params_list\n",
    "unpack_list = []\n",
    "\n",
    "# Iterate over best_params_list to unpack, store variables, and construct list of list \n",
    "for i in best_params_list:\n",
    "    run_date = i[0]\n",
    "    testing_end = i[1]\n",
    "    feature_lag = i[2]\n",
    "    # param_dict = dictionary\n",
    "    param_dict = i[3]\n",
    "    # unpack dictionary values using Key and assign to variable\n",
    "    n_estimators = param_dict['n_estimators']\n",
    "    min_samples_split = param_dict['min_samples_split']\n",
    "    max_features = param_dict['max_features']\n",
    "    max_depth = param_dict['max_depth']\n",
    "    # Append the current variables to unpack list\n",
    "    unpack_list.append([run_date, testing_end, feature_lag, n_estimators, min_samples_split, max_features, max_depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236beb0-31f2-4951-b1b5-b309390e1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the unpack_list was constructed correctly\n",
    "for i in unpack_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661248b6-68ef-4c07-84af-ec6b6e858cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constuct the DataFrame from the unpack_list\n",
    "column_names = ['RunDate', 'PeriodEndDate', 'FeatureLag', 'n_estimators', 'min_samples_split', 'max_features', 'max_depth']\n",
    "df_best_params = pd.DataFrame(unpack_list, columns=column_names)\n",
    "\n",
    "# Save historical file\n",
    "fl_name = 'AutoOutputFiles/df_best_params_' + testing_end + '.csv'\n",
    "df_best_params.to_csv(fl_name)\n",
    "\n",
    "# Save most recent file (may get imported into other notebooks)\n",
    "df_best_params.to_csv('AutoOutputFiles/df_best_params.csv')\n",
    "df_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc6134-d135-40e3-aac0-f0c498d13440",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in capture_stats_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df94a2b-b3a6-43d6-8989-6e0e63500257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constuct the DataFrame for capture statistics\n",
    "# 'EquityDays>=1%', 'EquityDays<=-1%' = Extreme Days\n",
    "column_names = [\n",
    "    'RunDate', 'PeriodEndDate', 'FeatureLag', \n",
    "    'EquityDays', 'EquityDaysPositive', 'EquityDaysNegative', \n",
    "    'StrategyDaysInEquity', 'StrategyDaysInCash', \n",
    "    'StrategyCapturePositive', 'StrategyCaptureNegative',\n",
    "    'EquityDays>=1%', 'EquityDays<=-1%', 'StrategyCaptureExtremePositive', 'StrategyCaptureExtremeNegative']\n",
    "df_capture_stats = pd.DataFrame(capture_stats_list, columns=column_names)\n",
    "\n",
    "# Save historical file\n",
    "fl_name = 'AutoOutputFiles/df_capture_stats_' + testing_end + '.csv'\n",
    "df_capture_stats.to_csv(fl_name)\n",
    "\n",
    "# Save most recent file (may get imported into other notebooks)\n",
    "df_capture_stats.to_csv('AutoOutputFiles/df_capture_stats.csv')\n",
    "df_capture_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfac5f6-c32a-4c00-9bb6-86c847880203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_descriptive_stats(data):\n",
    "    '''\n",
    "    Function calculates the 4 moments of the return distribution (mean, standard devation, skew, and kurtosis)\n",
    "    data parameter reflects the DataFrame with identified column\n",
    "         e.g. data = df_capture_stats['StrategyDaysInEquity']\n",
    "    \n",
    "    '''\n",
    "    mean = data.mean()\n",
    "    standard_dev = data.std()\n",
    "    skew = data.skew()\n",
    "    kurtosis = data.kurt()\n",
    "    \n",
    "    return mean, standard_dev, skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0563e3-610a-4d25-b1ee-e374aa5a2881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Capture Statistics For Current Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac063d1-1b8e-4a59-a668-fad621b2e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for StrategyDaysInEquity\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_capture_stats['StrategyDaysInEquity'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_capture_stats.hvplot.bar(\n",
    "    title = 'Strategy Days Invested In Equity By Feature Lag', \n",
    "    y='StrategyDaysInEquity', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce375041-7497-4249-8d0b-449894c3af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for StrategyDaysInCash\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_capture_stats['StrategyDaysInCash'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_capture_stats.hvplot.bar(\n",
    "    title = 'Strategy Days Invested In Cash By Feature Lag', \n",
    "    y='StrategyDaysInCash', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b386626-d4b8-49ce-a654-1e97e819e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for StrategyCapturePositive\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_capture_stats['StrategyCapturePositive'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_capture_stats.hvplot.bar(\n",
    "    title = 'Strategy Positive Days Capture By Feature Lag', \n",
    "    y='StrategyCapturePositive', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45402e26-da00-4c2d-a23e-43e12c752bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for StrategyCaptureNegative\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_capture_stats['StrategyCaptureNegative'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_capture_stats.hvplot.bar(\n",
    "    title = 'Strategy Negative Days Capture By Feature Lag', \n",
    "    y='StrategyCaptureNegative', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02ebda2-dd13-4a09-bd30-87e48fe67dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for StrategyCaptureExtremePositive\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_capture_stats['StrategyCaptureExtremePositive'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_capture_stats.hvplot.bar(\n",
    "    title = 'Strategy Extreme Positive Days Capture (>= 1%) By Feature Lag', \n",
    "    y='StrategyCaptureExtremePositive', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b706c-80c5-4458-bdd9-4e6bd2cd70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for StrategyCaptureExtremeNegative\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_capture_stats['StrategyCaptureExtremeNegative'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_capture_stats.hvplot.bar(\n",
    "    title = 'Strategy Extreme Negative Days Capture (<= 1%) By Feature Lag', \n",
    "    y='StrategyCaptureExtremeNegative', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eeaf47-1b07-4e2c-8726-243532a6b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for n_estimators\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_best_params['n_estimators'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_best_params.hvplot.bar(\n",
    "    title = 'N Estimators By Feature Lag', \n",
    "    y='n_estimators', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46c323-6324-4d18-95fe-cfc7ccbbb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for min_samples_split\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_best_params['min_samples_split'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_best_params.hvplot.bar(\n",
    "    title = 'Minimum Sample Splits By Feature Lag', \n",
    "    y='min_samples_split', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a9ae9-397c-4078-8c3e-62bffaea1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for max_depth\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_best_params['max_depth'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_best_params.hvplot.bar(\n",
    "    title = 'Maximum Depth By Feature Lag', \n",
    "    y='max_depth', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213ee08-73f3-4322-a75a-4b1a50964a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for max_features\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(df_best_params['max_features'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "df_best_params.hvplot.bar(\n",
    "    title = 'Maximum Features By Feature Lag', \n",
    "    y='max_features', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67596ce7-f653-4d29-b8aa-3b63b95fff1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Strategy Performance Results Current Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829b4063-b7e9-4b4b-8c24-982c311652d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the results_list that holds the strategy performance results was constructed correctly\n",
    "for x in results_list:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0c75a7-2863-416f-b56d-9e34ff9698da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the DataFrame to hold the strategy performance results from the results_list\n",
    "\n",
    "# 'Cumulative Return' is an array and not included in the below; not an issue since annualized return is available\n",
    "# \"For loop\" above now saves a csv file for each iteration and cummulative return can be obtained from those files\n",
    "df_strat_lag = pd.DataFrame(results_list, columns = ['RunDate', 'PeriodEndDate',\n",
    "    'FeatureLag', 'n_estimators', 'max_depth', 'max_features', 'random_state', 'verbose',\n",
    "    'Annual Return', 'Annual Volatility', 'Sharpe Ratio', \n",
    "    'Calmar Ratio', 'Max Drawdown', 'Sortino Ratio', 'Alpha', 'Beta'])\n",
    "\n",
    "# File with run_date retained for historical reord\n",
    "fl_nm = 'AutoOutputFiles/df_strat_lag_' + testing_end + '.csv'\n",
    "df_strat_lag.to_csv(fl_nm)\n",
    "\n",
    "# This file is imported into notebook 'Current_rfc_model.ipynb' and is overriden on each execution of this notebook\n",
    "df_strat_lag.to_csv('AutoOutputFiles/df_strat_lag.csv')\n",
    "df_strat_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f893e7-97e0-425f-8627-b3d42a678e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['FeatureLag','Annual Return','Annual Volatility','Sharpe Ratio','Calmar Ratio','Max Drawdown','Sortino Ratio','Alpha','Beta']\n",
    "plot_data = df_strat_lag[var_list]\n",
    "plot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41da5c4-669e-4355-9d03-d94cfea5ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for Annual Return\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(plot_data['Annual Return'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "# https://hvplot.holoviz.org/user_guide/Customization.html\n",
    "plot_data.hvplot.bar(\n",
    "    title = 'Strategy Annualized Return Per Feature Lag (Days)', \n",
    "    y='Annual Return', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d3612-3167-438e-9847-f15af9f49c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for Annual Volatility\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(plot_data['Annual Volatility'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "\n",
    "plot_data.hvplot.bar(\n",
    "    title = 'Strategy Annual Volatility Per Feature Lag (Days)', \n",
    "    y='Annual Volatility', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    "\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59242620-ff95-457c-b044-98f9c6149050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for Sharpe Ratio\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(plot_data['Sharpe Ratio'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS FOR FEATURE LAGS MAXIMUM DEPTH:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "plot_data.hvplot.bar(\n",
    "    title = 'Strategy Sharpe Ratio Per Feature Lag (Days)', \n",
    "    y='Sharpe Ratio', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)', \n",
    "    height=500,\n",
    "    width = 1500\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40862f25-7e1f-48ec-b752-ed78c6747c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for Sortino Ratio\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(plot_data['Sortino Ratio'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "plot_data.hvplot.bar(\n",
    "    title = 'Strategy Sortino Ratio Per Feature Lag (Days)', \n",
    "    y='Sortino Ratio', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)',\n",
    "    colorbar = True,\n",
    "    height=500,\n",
    "    width = 1500\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc043341-4e52-4474-98ed-be0d3fe21a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for Calmar Ratio\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(plot_data['Calmar Ratio'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "plot_data.hvplot.bar(\n",
    "    title = 'Strategy Calmar Ratio Per Feature Lag (Days)', \n",
    "    y='Calmar Ratio', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)',\n",
    "    colorbar = True,\n",
    "    height=500,\n",
    "    width = 1500\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9ad45-04bf-464b-a610-cfe51f9a4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for Max Drawdown\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(plot_data['Max Drawdown'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "plot_data.hvplot.bar(\n",
    "    title = 'Strategy Max Drawdown Per Feature Lag (Days)', \n",
    "    y='Max Drawdown', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)',\n",
    "    colorbar = True,\n",
    "    height=500,\n",
    "    width = 1500\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9cc70-c911-404f-bc83-b324aa2976a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for Calmar Ratio\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(plot_data['Calmar Ratio'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "plot_data.hvplot.bar(\n",
    "    title = 'Strategy Alpha Per Feature Lag (Days)', \n",
    "    y='Calmar Ratio', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)',\n",
    "    colorbar = True,\n",
    "    height=500,\n",
    "    width = 1500\n",
    ").opts(xrotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85312c9b-b3b2-4f66-90f7-c2b3a38fe26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate & Plot descriptive statistics for Beta\n",
    "mean, standard_dev, skew, kurtosis = calculate_descriptive_stats(plot_data['Beta'])\n",
    "\n",
    "print(f'DESCRIPTIVE STATISTICS:\\n')\n",
    "print(f'Mean = {mean}')\n",
    "print(f'Standard Deviation = {standard_dev}')\n",
    "print(f'Skew = {skew}')\n",
    "print(f'Kurtosis = {kurtosis}\\n')\n",
    "\n",
    "plot_data.hvplot.bar(\n",
    "    title = 'Strategy Beta Per Feature Lag (Days)', \n",
    "    y='Beta', \n",
    "    x='FeatureLag', \n",
    "    xlabel ='Feature Lag (Days)',\n",
    "    colorbar = True,\n",
    "    height=500,\n",
    "    width = 1500\n",
    ").opts(xrotation=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
